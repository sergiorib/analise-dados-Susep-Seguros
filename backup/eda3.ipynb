{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "28bc51ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIM !\n"
     ]
    }
   ],
   "source": [
    "# Importa a função para carregar pastas de trabalho\n",
    "from openpyxl import load_workbook \n",
    "\n",
    "# 1. Abrir a planilha\n",
    "# Substitua 'seu_arquivo.xlsx' pelo nome do seu arquivo.\n",
    "try:\n",
    "    workbook = load_workbook(r'C:\\Users\\User\\OneDrive\\Documentos\\GitHub\\analise-dados-susep-seguros\\doc\\eda.xlsx')\n",
    "except FileNotFoundError:\n",
    "    print(\"Erro: Arquivo 'seu_arquivo.xlsx' não encontrado.\")\n",
    "    # Você pode adicionar aqui a lógica para criar o arquivo se ele não existir,\n",
    "    # usando from openpyxl import Workbook e wb = Workbook().\n",
    "    # Para este exemplo, apenas saímos.\n",
    "    exit()\n",
    "\n",
    "# 2. Selecionar a Planilha (Sheet)\n",
    "# Você pode usar o nome da planilha ou a planilha ativa\n",
    "# Se o nome for 'Planilha1', use:\n",
    "sheet = workbook['Planilha1'] \n",
    "\n",
    "# Se quiser usar a planilha ativa (geralmente a primeira):\n",
    "# sheet = workbook.active \n",
    "\n",
    "# 3. Alterar o Conteúdo de uma Célula\n",
    "\n",
    "# Há duas formas principais de fazer referência à célula:\n",
    "# A) Usando notação de coluna/linha do Excel (ex: 'A1', 'B5'):\n",
    "sheet['W2'] = '77.12'\n",
    "\n",
    "# B) Usando indexação por linha e coluna (índice começa em 1):\n",
    "# A célula na linha 2, coluna 3 (que é a célula C2) receberá 'Alterado!'\n",
    "sheet.cell(row=2, column=24, value='23,88')\n",
    "\n",
    "# 4. Salvar a planilha\n",
    "# Você pode salvar no mesmo arquivo ou em um novo.\n",
    "# Se salvar no mesmo arquivo, ele será sobrescrito.\n",
    "workbook.save(r'C:\\Users\\User\\OneDrive\\Documentos\\GitHub\\analise-dados-susep-seguros\\doc\\eda.xlsx')\n",
    "\n",
    "print(\"FIM !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaeca595",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import nan\n",
    "import pandas as pd\n",
    "from charset_normalizer import from_path \n",
    "import re \n",
    "from pandas import DataFrame, Series\n",
    "from typing import Dict, Any, Tuple, Optional, Union\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf601fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config_path = r\"C:\\Users\\User\\OneDrive\\Documentos\\GitHub\\analise-dados-susep-seguros\\doc\"\n",
    "config_file = r\"\\eda.xlsx\"\n",
    "result_path = r\"C:\\Users\\User\\OneDrive\\Documentos\\GitHub\\analise-dados-susep-seguros\\doc\"\n",
    "result_file = r\"\\eda_result.xlsx\"\n",
    "path_dados  = r\"C:\\Users\\User\\OneDrive\\Documentos\\GitHub\\analise-dados-susep-seguros\\data\"\n",
    "\n",
    "sheet_file = config_path+config_file\n",
    "sheet_fields = ('tab_nome','tab_descricao','tab_arquivo','tab_tamanho','tab_linhas','tab_colunas','tab_tipo','cpo_nome','cpo_desc','cpo_tipo','cpo_tamanho','cpo_formato','cpo_pk','cpo_fk','cpo_tab_fk','cpo_vazio','cpo_valores','cpo_limite','cpo_regex','rsp_vazio','rsp_unico','rsp_repetido','rsp_formato','rsp_invalido','rsp_limite','rsp_min','rsp_max','rsp_referencial')\n",
    "df_eda_sheet = pd.read_excel(sheet_file,header=None, skiprows=1, names=sheet_fields)\n",
    "df_eda_sheet.columns = df_eda_sheet.columns.str.lower() \n",
    "df_eda_sheet[\"cpo_limite\"] = df_eda_sheet[\"cpo_limite\"].fillna('')\n",
    "df_eda_sheet[\"cpo_limite\"] = df_eda_sheet[\"cpo_limite\"].astype(str)\n",
    "\n",
    "nome_tabela = \"\"\n",
    "nome_tabela_atual = \"\"\n",
    "for index, sheet_row in df_eda_sheet.iterrows():\n",
    "\n",
    "    if (not pd.isna(sheet_row['tab_nome']) and not sheet_row['tab_nome'] == \"Tabela\"): \n",
    "        nome_tabela = sheet_row['tab_nome']\n",
    "\n",
    "        # Le os dados \n",
    "        nome_arquivo = sheet_row['tab_arquivo']\n",
    "        file_path = path_dados + '/' + nome_arquivo\n",
    "        encode = \"\"\n",
    "        separador = \";\"\n",
    "        try:\n",
    "            if len(encode) == 0: \n",
    "               detectado = from_path(str(file_path)).best() \n",
    "               encoding_detectado = detectado.encoding \n",
    "            else: \n",
    "               encoding_detectado = encode\n",
    "        except Exception:\n",
    "            encoding_detectado = 'utf-8' \n",
    "        # data Load    \n",
    "        df_dados = pd.read_csv(file_path,encoding=encoding_detectado,sep=separador,engine='python')\n",
    "        df_dados.columns = df_dados.columns.str.lower() \n",
    "\n",
    "    if (pd.isna(sheet_row['cpo_nome']) or sheet_row['cpo_nome'] == \"Campo\"): \n",
    "        continue \n",
    "    \n",
    "    total_registros = len(df_dados)\n",
    "    nome_campo = sheet_row['cpo_nome']\n",
    "    # -----------------------------------------------------\n",
    "    # Vazios: Brancos, nulos e zerados\n",
    "    # -----------------------------------------------------\n",
    "\n",
    "    percentual_problema = 0 \n",
    "    cond_nulos = pd.isna(df_dados[nome_campo])\n",
    "\n",
    "    cond_vazios = (df_dados[nome_campo].astype(str).str.strip() == '')\n",
    "    cond_zeros = (df_dados[nome_campo] == 0)\n",
    "    cond_zeros_str = (df_dados[nome_campo] == 0) | (df_dados[nome_campo] == '0')\n",
    "    mascara_total = cond_nulos | cond_vazios | cond_zeros\n",
    "    percentual_problema = mascara_total.mean() \n",
    "    df_eda_sheet.loc[index, 'rsp_vazio'] = percentual_problema\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # Valores Únicos\n",
    "    # -----------------------------------------------------\n",
    "    contagem_unicos = df_dados[nome_campo].nunique()\n",
    "    prcentual_unicos = (contagem_unicos / total_registros) \n",
    "    df_eda_sheet.loc[index, 'rsp_unico'] = prcentual_unicos\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # Valores Repetidos\n",
    "    # -----------------------------------------------------\n",
    "    mascara_repetidos = df_dados[nome_campo].duplicated(keep=False)\n",
    "    contagem_repetidos = mascara_repetidos.sum()\n",
    "    percentual_repetidos = (contagem_repetidos / total_registros)\n",
    "    df_eda_sheet.loc[index, 'rsp_repetido'] = percentual_repetidos\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # Formato (Regex)\n",
    "    # -----------------------------------------------------\n",
    "    regex = sheet_row['cpo_regex']\n",
    "    coluna_limpa = df_dados[nome_campo].astype(str).str.replace(r'\\.0', '', regex=True).str.strip()\n",
    "    mascara_sucesso = coluna_limpa.str.match(str(regex), na=False)\n",
    "    mascara_falha = ~mascara_sucesso\n",
    "    proporcao_sucesso = mascara_falha.mean()\n",
    "    df_eda_sheet.loc[index, 'rsp_formato'] = proporcao_sucesso\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # Valores inválidos em uma lista \n",
    "    # -----------------------------------------------------\n",
    "    lista_valores = sheet_row['cpo_valores']\n",
    "    if not pd.isna(lista_valores): \n",
    "        lista_validos = [item.strip().upper() for item in lista_valores.split(';')]\n",
    "        coluna_para_validar = df_dados[nome_campo].astype(str).str.upper()\n",
    "        mascara_sucesso = coluna_para_validar.isin(lista_validos)        \n",
    "        mascara_falha = ~mascara_sucesso\n",
    "        percentual_falha = mascara_falha.mean()\n",
    "        df_eda_sheet.loc[index, 'rsp_invalido'] = percentual_falha\n",
    "    else: \n",
    "        df_eda_sheet.loc[index, 'rsp_invalido'] = \"\"\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # Limites de valores \n",
    "    # -----------------------------------------------------\n",
    "    limite_string = sheet_row['cpo_limite']\n",
    "    if pd.isna(limite_string): \n",
    "\n",
    "        limites = re.findall(r'\\d+', limite_string)\n",
    "        if len(limites) != 2:\n",
    "            print(f\"ERRO: Formato de limite inválido ({limite_string}). Esperado 'MÍNIMO MÁXIMO'.\")\n",
    "            percentual_erro = \"\" \n",
    "        else:\n",
    "            # Converte os limites para FLOAT (ponto flutuante)\n",
    "            try:\n",
    "                limite_min = float(limites[0])\n",
    "                limite_max = float(limites[1])\n",
    "            except ValueError:\n",
    "                print(f\"ERRO: Limites encontrados ({limites}) não são números válidos.\")\n",
    "                percentual_erro = \"\"\n",
    "        coluna_numerica = pd.to_numeric(df_dados[nome_campo], errors='coerce')\n",
    "        mascara_validacao = pd.notna(coluna_numerica)\n",
    "        total_para_validar = mascara_validacao.sum()\n",
    "        if total_para_validar == 0:\n",
    "            percentual_erro = 0.0\n",
    "        else:\n",
    "            cond_min = (coluna_numerica >= limite_min) \n",
    "            cond_max = (coluna_numerica <= limite_max)\n",
    "            mascara_falha_limite = (~(cond_min & cond_max)) & mascara_validacao\n",
    "            percentual_erro = (mascara_falha_limite.sum() / total_para_validar) \n",
    "        df_eda_sheet.loc[index, 'rsp_limite'] = percentual_erro\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # Valores Minimo e Maximo da coluna\n",
    "    # -----------------------------------------------------\n",
    "    coluna_numerica = pd.to_numeric(df_dados[nome_campo], errors='coerce')\n",
    "    valor_minimo = coluna_numerica.min()\n",
    "    valor_maximo = coluna_numerica.max()\n",
    "    if not pd.isna(valor_minimo):\n",
    "        df_eda_sheet.loc[index, 'rsp_min'] = valor_minimo\n",
    "    if not pd.isna(valor_maximo): \n",
    "        df_eda_sheet.loc[index, 'rsp_max'] = valor_maximo\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # Integridade referencial\n",
    "    # -----------------------------------------------------\n",
    "    # Abre a tabela relacionada e procura pela FK  \n",
    "    #rsp_relacional 'cpo_fk','cpo_tab_fk'\n",
    "    if sheet_row['cpo_fk'] == \"Sim\": \n",
    "        nome_tabela_relacionada = sheet_row['cpo_tab_fk']\n",
    "        file_path_fk = path_dados + '/' + nome_tabela_relacionada + \".csv\"\n",
    "        encode = \"windows-1252\"\n",
    "        separador = \";\"\n",
    "        try:\n",
    "            if len(encode) == 0: \n",
    "                detectado = from_path(str(file_path)).best() \n",
    "                encoding_detectado = detectado.encoding \n",
    "            else: \n",
    "                encoding_detectado = encode\n",
    "        except Exception:\n",
    "            encoding_detectado = 'utf-8'  \n",
    "        df_dados_fk = pd.read_csv(file_path_fk,encoding=encoding_detectado,sep=separador,engine='python')\n",
    "        df_dados_fk.columns = df_dados_fk.columns.str.lower() \n",
    "        chaves_primarias_validas = set(df_dados_fk[nome_campo].dropna().unique())\n",
    "        registros_a_checar = df_dados[nome_campo].dropna()\n",
    "        total_registros_checado = len(registros_a_checar)\n",
    "        if total_registros_checado == 0:\n",
    "            percentual_integridade = 0.0\n",
    "        else:\n",
    "            mascara_sucesso_relacional = registros_a_checar.isin(chaves_primarias_validas)\n",
    "            proporcao_sucesso = mascara_sucesso_relacional.mean()\n",
    "            percentual_integridade = proporcao_sucesso \n",
    "            df_eda_sheet.loc[index, 'rsp_referencial'] = percentual_integridade\n",
    "        \n",
    "    # Salva a planilha de saida\n",
    "    df_eda_sheet.to_excel(result_path+result_file, sheet_name='resultados_eda', index=False,)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analise-seguros-56jiVyUg-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
